{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom keras.layers.core import Dense, Dropout\nfrom transformers import TFBertModel,  BertConfig, BertTokenizerFast\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/dataset-modified/train_modified.csv')\nvalid = pd.read_csv('../input/dataset-modified/val_modified.csv')\ntest = pd.read_csv('../input/dataset-modified/test_modified.csv')\n\nxtrain, ytrain = train.Comment.values, train.Emotion.values\nxvalid, yvalid = valid.Comment.values, valid.Emotion.values\nxtest, ytest = test.Comment.values, test.Emotion.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = 'bert-base-multilingual-cased')\nmax_len = 200\n\nxtrain_pad = tokenizer(\n    text=train['Comment'].to_list(),\n    add_special_tokens=True,\n    max_length=max_len,\n    truncation=True,\n    padding=True, \n    return_tensors='tf',\n    return_token_type_ids = False,\n    return_attention_mask = False,\n    verbose = True)\n\nxvalid_pad = tokenizer(\n    text=valid['Comment'].to_list(),\n    add_special_tokens=True,\n    max_length=max_len,\n    truncation=True,\n    padding=True, \n    return_tensors='tf',\n    return_token_type_ids = False,\n    return_attention_mask = False,\n    verbose = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model(transformer):\n    input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n    sequence_output = transformer(input_ids)[0]\n    cls_token = sequence_output[:, 0, :]\n    out = Dense(4, activation='softmax')(cls_token)\n\n    model = Model(inputs=input_ids, outputs=out)\n    loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n    model.compile(Adam(lr=1e-5, beta_2 = 0.99), loss=loss, metrics=['accuracy'])\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy', dtype=tf.float32)]\nloss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\nwith strategy.scope():\n    model_name = 'bert-base-multilingual-cased'\n    config = BertConfig.from_pretrained(model_name)\n    config.output_hidden_states = False\n    transformer_model = TFBertModel.from_pretrained(model_name, config = config)\n    model = build_model(transformer_model)\n    \nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(xtrain_pad['input_ids'], ytrain,epochs=100, validation_data= (xvalid_pad['input_ids'], yvalid), batch_size=128*strategy.num_replicas_in_sync) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_learning_curve(history):\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    accuracy = history.history['accuracy']\n    val_accuracy = history.history['val_accuracy']\n    \n    plt.plot(loss, label='loss')\n    plt.plot(val_loss,label='val loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(['loss','val_loss'],loc='upper right')\n    plt.show()\n \n    \n    plt.plot(accuracy, label='accuracy')\n    plt.plot(val_accuracy,label='val accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(['accuracy','val accuracy'],loc='upper right')\n    plt.show()\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_learning_curve(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x = tokenizer(\n    text=test['Comment'].to_list(),\n    add_special_tokens=True,\n    max_length=max_len,\n    truncation=True,\n    padding=True, \n    return_tensors='tf',\n    return_token_type_ids = False,\n    return_attention_mask = False,\n    verbose = True)\n\nmodel_eval = model.evaluate(\n    x={'input_ids': test_x['input_ids']},\n    y=ytest\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('kaggle/output/bert_model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}